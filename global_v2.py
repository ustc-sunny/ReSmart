# -*- coding: utf-8 -*-
"""
Created on Mon Oct  9 21:30:06 2023

@author: 94481
"""

import random
import numpy as np # type: ignore
import math
import matplotlib.pyplot as plt
from scipy.stats import beta
from tqdm import *
#GS UCB TS

class Arm:
    def __init__(self, arm_id, num_players):
        self.arm_id = arm_id
#         self.matched_players = []
        self.player_preference = np.random.permutation(np.arange(0, num_players)) #player_preferenceç¬¬iä¸ªè¡¨ç¤ºç¬¬iä¸ªplayerçš„æ’åï¼Œè¶Šå°è¶Šå¥½


class Market:
    def __init__(self, num_players, num_arms, num_time_slots, r, L):
        self.num_players = num_players
        self.num_arms = num_arms
        self.num_time_slots = num_time_slots
        self.L = L
        self.arms = [Arm(i, self.num_players) for i in range(self.num_arms)]
        # for arm in self.arms:
        #     arm.player_preference = self.arms[0].player_preference
        self.choosing_result = np.full((self.num_time_slots, self.num_players), -1)  # ç”¨äºè®°å½•æ¯ä¸ªæ—¶é—´æ­¥çš„é€‰æ‹©ç»“æœ
        self.choosing_result[0] = np.random.randint(0, self.num_arms, self.num_players)
        self.matching_result = np.full((self.num_time_slots, self.num_players), -1)  # åˆå§‹åŒ–matching_resultçŸ©é˜µ
        self.matching_result[0] = self.choosing_result[0]
        self.alpha = np.ones((self.num_players, self.num_arms))
        self.beta = np.ones((self.num_players, self.num_arms))
        self.theta = np.zeros((self.num_players, self.num_arms))
        self.k = 1
        self.feasible_set = [[] for _ in range(num_players)]
        self.r= r
        self.X = np.zeros((num_players, num_arms))
        self.Y = np.zeros((num_players, num_arms))
        self.candidate_arm = [[] for _ in range(num_arms)]

        #self.regrets = [[] for _ in range(num_players)]
        self.regrets = np.zeros((self.num_players, self.num_time_slots))
        self.utilities = np.zeros((self.num_players, self.num_time_slots))
    def update_r(self):
        r1 = np.random.uniform(low=0, high=1, size=(self.num_players, self.num_arms))
        self.r = r1
    def update_feasible_set(self, time_slot):
        self.feasible_set = [[] for _ in range(self.num_players)]
        #å°†å½“å‰åŒ¹é…çš„æ¯ä¸ªarmçš„æœ€å¤§preferenceæ‰€å¯¹åº”çš„player_idè¾“å‡ºæˆä¸€ç»´çŸ©é˜µ
        current_max_arm_pre = [-1] * self.num_arms # åˆå§‹åŒ–ä¸º-1
        for i in range(self.num_players):
            mi = self.matching_result[time_slot -1][i]#############################time_slot == 1 çš„æ—¶å€™
            if mi == -1:#if no match for player i
                continue
            max_mj = current_max_arm_pre[mi]
            if max_mj == -1:
                current_max_arm_pre[mi] = i
            elif np.where(self.arms[mi].player_preference == i)[0] < np.where(self.arms[mi].player_preference == max_mj)[0]:
                current_max_arm_pre[mi] = i
        #start to update feasible set
        for j in range(self.num_arms):
            if current_max_arm_pre[j] != -1:
                k = 0
                while self.arms[j].player_preference[k] != current_max_arm_pre[j]:
                    #print(self.arms[j].player_preference[k])
                    self.feasible_set[self.arms[j].player_preference[k]].append(j)
                    k += 1

    def run_market(self):
        for arm in self.arms:
            print(arm.player_preference)
        for time_slot in tqdm(range(1, self.num_time_slots)):
            #print(time_slot)
            #start algorithm
            if self.k == 1:
               #Set ğ‘›ğ‘¡ğ‘–,ğ‘— = 0, ğ›¼ğ‘–,ğ‘— = 1, ğ›½ğ‘–,ğ‘— = 1, âˆ€ğ‘– âˆˆ T, âˆ€ğ‘— âˆˆ U
               #####nij??
               self.alpha = np.ones((self.num_players, self.num_arms))
               self.beta = np.ones((self.num_players, self.num_arms))
               #âˆ€ğ‘– âˆˆ T, ğ‘1 (ğ‘–) = ğ‘—, ğ‘— âˆ¼ U uniformly at random.
               self.update_r()
               self.choosing_result[time_slot - 1] = np.random.randint(0, self.num_arms, self.num_players)
               self.matching_result[time_slot - 1] = self.choosing_result[time_slot - 1]
            #Distributed Task Matching using ThompsonSampling (DTTS) start.
            #print(self.matching_result)
            #Update the feasible set
            self.update_feasible_set(time_slot)
            #print(self.feasible_set)
            self.X = np.zeros((self.num_players, self.num_arms))
            self.Y = np.zeros((self.num_players, self.num_arms))
            self.candidate_arm = [[] for _ in range(self.num_arms)]
            for i in range(self.num_players):
                #ğœƒğ‘–,ğ‘— âˆ¼ ğµğ‘’ (ğ›¼ğ‘–,ğ‘—, ğ›½ğ‘–,ğ‘—)
                for j in range(self.num_arms):
                    self.theta[i][j] = np.random.beta(self.alpha[i][j], self.beta[i][j])
                    #self.theta[i][j] = np.random.normal(loc=self.r[i][j], scale=10, size=None)
                #Draw ğµğ‘–(ğ‘¡) âˆ¼ ğµğ‘’ğ‘Ÿ(ğœ†) independently.
                lambda_prob = 0.1    #lambda
                if random.random() < lambda_prob:#lambda
                    #set at(i) = at-1(i)
                    self.choosing_result[time_slot][i] = self.choosing_result[time_slot - 1][i]
                else:
                    #updating_feasible_set is in initialization
                    #Attempt to propose the matching request to ğ‘ âˆˆ ğ¹ğ‘¡ (ğ‘–) with the maximum ğœƒğ‘–,ğ‘— .
                    if not self.feasible_set:
                        self.choosing_result[time_slot][i] = self.choosing_result[time_slot - 1][i]
                    else:
                        a = self.choosing_result[time_slot - 1][i]## Let a = self.choosing_result[time_slot - 1][i]
                        for j in range(self.num_arms):
                            if j in self.feasible_set[i] and self.theta[i][j] > self.theta[i][a]:
                                a = j
                        #Set ğ‘ğ‘¡ (ğ‘–) = ğ‘
                        self.choosing_result[time_slot][i] = a
                self.candidate_arm[self.choosing_result[time_slot][i]].append(i)
                #if ğœ‹Â¯ğ‘ğ‘¡ (ğ‘–)(ğ‘–) â‰»ğ‘ğ‘¡ (ğ‘–) ğœ‹Â¯ğ‘–â€² (ğ‘–),ğ‘–â€² âˆˆ Tğ‘¡ğ‘–,j

            for i in range(self.num_players):
                matching_result = self.choosing_result[time_slot][i]
                if self.candidate_arm[matching_result][np.argmin([np.where(self.arms[matching_result].player_preference == k) for k in self.candidate_arm[matching_result]])] == i:
                    #Obtain a utility ğ‘‹t(i, mt(i))ï¼Œæ­£æ€åˆ†å¸ƒ
                    #self.X[i][a] = np.random.noraml(self.r[i][a], 1)########æ­£å¤ªåˆ†å¸ƒå¤§äº1ä¸èƒ½åç»­ç”¨ä¼¯åŠªåˆ©
                    #draw ğ‘Œğ‘¡(i, mt(i))
                    #print(self.X[i][a])
                    if random.random() < self.r[i][matching_result]:
                        self.Y[i][matching_result] = 1
                    else:
                        self.Y[i][matching_result] = 0
                    #Update parameter of Beta distribution ğµğ‘’:
                    self.alpha[i][matching_result] += self.Y[i][matching_result]
                    self.beta[i][matching_result] = self.beta[i][matching_result] + 1 - self.Y[i][matching_result]
                    #update regret
                    self.regrets[i][time_slot] = self.regrets[i][time_slot - 1] + min(self.r[i]) - self.Y[i][matching_result]
                    self.utilities[i][time_slot] = self.utilities[i][time_slot - 1] + self.Y[i][matching_result]
                    #self.regrets[i][time_slot] = min(self.r[i]) - self.Y[i][matching_result]
            if self.k <= self.L:########self.L???
                self.k += 1
            else:
                self.k = 1

def main():
    # è®¾ç½®å‚æ•°
    num_players = 50
    num_arms = 50
    num_episodes = 1
    sigle_time_slots = 500
    stable_index = []
    num_time_slots = sigle_time_slots * num_episodes
    L = 500
    # for round in range(num_instance):    
    #     # åˆ›å»ºå¸‚åœºå¹¶è¿è¡Œ
    #     print(round)
    #     market = Market(num_players, num_arms, num_episodes, num_time_slots, gamma)
    #     market.run_market()
    #     stable_index.append(market.stable_index)
        
    
    # stable_sum = np.zeros(num_episodes)
    # for round in range(num_instance):
    #     instance = stable_index[round]
    #     stable_sum = stable_sum + instance
        
    # stable_mean = stable_sum/num_instance
    
    r = np.random.uniform(low=0, high=1, size=(num_players, num_arms))
    market = Market(num_players, num_arms, num_time_slots, r, L)
    market.run_market()

    last_regret = market.regrets[:, -1]
    max_index = np.argmax(np.abs(last_regret))
    print(market.regrets)
    time_slots = range(1, num_time_slots + 1)  # æ—¶é—´æ§½
    av_regret = np.sum(market.regrets, axis=0)/len(market.regrets[0])
    av_utility = np.sum(market.utilities, axis=0)/len(market.utilities[0])
    #plt.plot(time_slots, av_regret, marker = 'o')
    plt.plot(time_slots, av_utility, marker = 'o')
    plt.xlabel('time')
    plt.ylabel('regret')
    plt.title('regret')
    plt.legend()
    plt.grid(True)
    plt.show()
    #stable_index.append(market.stable_index)
    # å¹³å‡ç´¯ç§¯å¥–åŠ±æŸ±çŠ¶å›¾
    # å‡†å¤‡æ•°æ®
    # x_data = range(1, num_episodes * num_time_slots)
    # y_TS_UCB = market.Average_cumulative_reward
    # y_TS = market.Average_cumulative_reward
    # y_UCB = market.Average_cumulative_reward
    # #1.å°†xè½´è½¬æ¢ä¸ºæ•°å€¼
    # x = np.arange(len(x_data))
    # #2.è®¾ç½®å›¾å½¢çš„å®½åº¦
    # width = 0.2
    # #_______________ç¡®å®šxèµ·å§‹ä½ç½®
    # #TS-UCBèµ·å§‹ä½ç½®
    # x_TS_UCB = x - width
    # #TSèµ·å§‹ä½ç½®
    # x_TS = x
    # #UCBèµ·å§‹ä½ç½®
    # x_UCB = x + width
    # #_______________åˆ†åˆ«ç»˜åˆ¶å›¾å½¢
    # #TS-UCBå›¾å½¢
    # plt.bar(x_TS_UCB, y_TS_UCB, width = width, label = 'TS-UCB', hatch = "...", color = 'w', edgecolor = "k")
    # #TSå›¾å½¢
    # plt.bar(x_TS, y_TS, width = width, label = 'TS', hatch = "++", color = 'w', edgecolor = "k")
    # #UCBå›¾å½¢
    # plt.bar(x_UCB, y_UCB, width = width, label = 'UCB', hatch = "XX", color = 'w', edgecolor = "k")
    # plt.title("Average cumulative reward")
    # plt.xlabel('Timeslot')
    # plt.ylabel('Average cumulative reward')
    # # æ˜¾ç¤º
    # plt.show()

    # å¹³å‡stable regretæŠ˜çº¿å›¾
    # å¹³å‡stable regretæŠ˜çº¿å›¾
    # x_data = range(1, num_time_slots)
    # y_data = market.Regret
    # plt.plot(x_data, y_data, linewidth=1, label="1")
    # plt.title("Average stable regret")
    # plt.xlabel('timeslot')
    # plt.ylabel('Average stable regret')
    # plt.show
main()